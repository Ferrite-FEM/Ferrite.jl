<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Assembly · Ferrite.jl</title><meta name="title" content="Assembly · Ferrite.jl"/><meta property="og:title" content="Assembly · Ferrite.jl"/><meta property="twitter:title" content="Assembly · Ferrite.jl"/><meta name="description" content="Documentation for Ferrite.jl."/><meta property="og:description" content="Documentation for Ferrite.jl."/><meta property="twitter:description" content="Documentation for Ferrite.jl."/><meta property="og:url" content="https://ferrite-fem.github.io/Ferrite.jl/stable/topics/assembly/"/><meta property="twitter:url" content="https://ferrite-fem.github.io/Ferrite.jl/stable/topics/assembly/"/><link rel="canonical" href="https://ferrite-fem.github.io/Ferrite.jl/stable/topics/assembly/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Ferrite.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Ferrite.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/">Tutorials overview</a></li><li><a class="tocitem" href="../../tutorials/heat_equation/">Heat equation</a></li><li><a class="tocitem" href="../../tutorials/linear_elasticity/">Linear elasticity</a></li><li><a class="tocitem" href="../../tutorials/incompressible_elasticity/">Incompressible elasticity</a></li><li><a class="tocitem" href="../../tutorials/hyperelasticity/">Hyperelasticity</a></li><li><a class="tocitem" href="../../tutorials/plasticity/">Von Mises plasticity</a></li><li><a class="tocitem" href="../../tutorials/transient_heat_equation/">Transient heat equation</a></li><li><a class="tocitem" href="../../tutorials/computational_homogenization/">Computational homogenization</a></li><li><a class="tocitem" href="../../tutorials/stokes-flow/">Stokes flow</a></li><li><a class="tocitem" href="../../tutorials/porous_media/">Porous media</a></li><li><a class="tocitem" href="../../tutorials/ns_vs_diffeq/">Incompressible Navier-Stokes equations via DifferentialEquations.jl</a></li><li><a class="tocitem" href="../../tutorials/reactive_surface/">Reactive surface</a></li><li><a class="tocitem" href="../../tutorials/linear_shell/">Linear shell</a></li><li><a class="tocitem" href="../../tutorials/dg_heat_equation/">Discontinuous Galerkin heat equation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">Topic guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../">Topic guide overview</a></li><li><a class="tocitem" href="../fe_intro/">Introduction to FEM</a></li><li><a class="tocitem" href="../reference_shapes/">Reference shapes</a></li><li><a class="tocitem" href="../FEValues/">FEValues</a></li><li><a class="tocitem" href="../degrees_of_freedom/">Degrees of Freedom</a></li><li><a class="tocitem" href="../sparse_matrix/">Sparsity pattern and sparse matrices</a></li><li class="is-active"><a class="tocitem" href>Assembly</a><ul class="internal"><li><a class="tocitem" href="#Assembler"><span><code>Assembler</code></span></a></li><li><a class="tocitem" href="#Pseudo-code-for-efficient-assembly"><span>Pseudo-code for efficient assembly</span></a></li><li><a class="tocitem" href="#Comparison-of-assembly-strategies"><span>Comparison of assembly strategies</span></a></li></ul></li><li><a class="tocitem" href="../boundary_conditions/">Boundary and initial conditions</a></li><li><a class="tocitem" href="../constraints/">Affine constraints</a></li><li><a class="tocitem" href="../grid/">Grid</a></li><li><a class="tocitem" href="../export/">Export</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">API reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../reference/">Reference overview</a></li><li><a class="tocitem" href="../../reference/quadrature/">Quadrature</a></li><li><a class="tocitem" href="../../reference/interpolations/">Interpolation</a></li><li><a class="tocitem" href="../../reference/fevalues/">FEValues</a></li><li><a class="tocitem" href="../../reference/dofhandler/">Degrees of Freedom</a></li><li><a class="tocitem" href="../../reference/sparsity_pattern/">Sparsity pattern and sparse matrices</a></li><li><a class="tocitem" href="../../reference/assembly/">Assembly</a></li><li><a class="tocitem" href="../../reference/boundary_conditions/">Boundary conditions</a></li><li><a class="tocitem" href="../../reference/grid/">Grid &amp; AbstractGrid</a></li><li><a class="tocitem" href="../../reference/export/">Postprocessing</a></li><li><a class="tocitem" href="../../reference/utils/">Development utility functions</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">How-to guides</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../howto/">How-to guide overview</a></li><li><a class="tocitem" href="../../howto/postprocessing/">Post processing and visualization</a></li><li><a class="tocitem" href="../../howto/threaded_assembly/">Multi-threaded assembly</a></li></ul></li><br><li><a class="tocitem" href="../../gallery/">Code gallery</a></li><li><a class="tocitem" href="../../devdocs/">Developer documentation</a></li><li><a class="tocitem" href="../../cited-literature/">Cited literature</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Topic guides</a></li><li class="is-active"><a href>Assembly</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Assembly</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Ferrite-FEM/Ferrite.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Ferrite-FEM/Ferrite.jl/blob/master/docs/src/topics/assembly.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="man-assembly"><a class="docs-heading-anchor" href="#man-assembly">Assembly</a><a id="man-assembly-1"></a><a class="docs-heading-anchor-permalink" href="#man-assembly" title="Permalink"></a></h1><p>When the local stiffness matrix and force vector have been calculated they should be assembled into the global stiffness matrix and the global force vector. This is just a matter of adding the local matrix and vector to the global one, at the correct place. Consider e.g. assembling the local stiffness matrix <code>ke</code> and the local force vector <code>fe</code> into the global <code>K</code> and <code>f</code> respectively. These should be assembled into the row/column which corresponds to the degrees of freedom for the cell:</p><pre><code class="language-julia hljs">K[celldofs, celldofs] += ke
f[celldofs]           += fe</code></pre><p>where <code>celldofs</code> is the vector containing the degrees of freedom for the cell. The method above is very inefficient – it is especially costly to index into the sparse matrix <code>K</code> directly (see <a href="#Comparison-of-assembly-strategies">Comparison of assembly strategies</a> for details). Therefore we will instead use an <code>Assembler</code> that will help with the assembling of both the global stiffness matrix and the global force vector. It is also often convenient to create the sparse matrix just once, and reuse the allocated matrix. This is useful for e.g. iterative solvers or time dependent problems where the sparse matrix structure, or <a href="../../reference/sparsity_pattern/#Sparsity-pattern-and-sparse-matrices">Sparsity Pattern</a> will stay the same in every iteration/time step.</p><h2 id="Assembler"><a class="docs-heading-anchor" href="#Assembler"><code>Assembler</code></a><a id="Assembler-1"></a><a class="docs-heading-anchor-permalink" href="#Assembler" title="Permalink"></a></h2><p>Assembling efficiently into the sparse matrix requires some extra workspace. This workspace is allocated in an <code>Assembler</code>. <a href="../../reference/assembly/#Ferrite.start_assemble"><code>start_assemble</code></a> is used to create an <code>Assembler</code>:</p><pre><code class="language-julia hljs">A = start_assemble(K)
A = start_assemble(K, f)</code></pre><p>where <code>K</code> is the global stiffness matrix, and <code>f</code> the global force vector. It is optional to pass the force vector to the assembler – sometimes there is no need to assemble a global force vector.</p><p>The <a href="../../reference/assembly/#Ferrite.assemble!"><code>assemble!</code></a> function is used to assemble element contributions to the assembler. For example, to assemble the element tangent stiffness <code>ke</code> and the element force vector <code>fe</code> to the assembler <code>A</code>, the following code can be used:</p><pre><code class="language-julia hljs">assemble!(A, celldofs, ke)
assemble!(A, celldofs, ke, fe)</code></pre><p>which perform the following operations in an efficient manner:</p><pre><code class="language-julia hljs">K[celldofs, celldofs] += ke
f[celldofs]           += fe</code></pre><h2 id="Pseudo-code-for-efficient-assembly"><a class="docs-heading-anchor" href="#Pseudo-code-for-efficient-assembly">Pseudo-code for efficient assembly</a><a id="Pseudo-code-for-efficient-assembly-1"></a><a class="docs-heading-anchor-permalink" href="#Pseudo-code-for-efficient-assembly" title="Permalink"></a></h2><p>Quite often the same sparsity pattern can be reused multiple times. For example:</p><ul><li>For time-dependent problems the pattern can be reused for all timesteps</li><li>For non-linear problems the pattern can be reused for all iterations</li></ul><p>In such cases it is enough to construct the global matrix <code>K</code> once. Below is some pseudo-code for how to do this for a time-dependent problem:</p><pre><code class="language-julia hljs">K = allocate_matrix(dh)
f = zeros(ndofs(dh))

for t in 1:timesteps
    A = start_assemble(K, f) # start_assemble zeroes K and f
    for cell in CellIterator(dh)
        ke, fe = element_routine(...)
        assemble!(A, celldofs(cell), ke, fe)
    end
    # Apply boundary conditions and solve for u(t)
    # ...
end</code></pre><h2 id="Comparison-of-assembly-strategies"><a class="docs-heading-anchor" href="#Comparison-of-assembly-strategies">Comparison of assembly strategies</a><a id="Comparison-of-assembly-strategies-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison-of-assembly-strategies" title="Permalink"></a></h2><p>As discussed above there are various ways to assemble the local matrix into the global one. In particular, it was mentioned that naive indexing is very inefficient and that using an assembler is faster. To put some concrete numbers to these statements we will compare some strategies in this section. First we compare just a single assembly operation (e.g. assembling an already computed local matrix) and then to relate this to a more realistic scenario we compare the full matrix assembly including the integration of all the elements.</p><div class="admonition is-info"><header class="admonition-header">Pre-allocated global matrix</header><div class="admonition-body"><p>All strategies that we compare below uses a pre-allocated global matrix <code>K</code> with the correct sparsity pattern. Starting with something like <code>K = spzeros(ndofs(dh), ndofs(dh))</code> and then inserting entries is excruciatingly slow due to the sparse data structure so this method is not even considered.</p></div></div><p>For the comparison we need a representative global matrix to assemble into. In the following setup code we create a grid with triangles and a DofHandler with a quadratic scalar field. From this we instantiate the global matrix.</p><pre><code class="language-julia hljs">using Ferrite

# Quadratic scalar interpolation
ip = Lagrange{RefTriangle, 2}()

# DofHandler
const N = 100
grid = generate_grid(Triangle, (N, N))
const dh = DofHandler(grid)
add!(dh, :u, ip)
close!(dh)

# Global matrix and a corresponding assembler
const K = allocate_matrix(dh)</code></pre><h4 id="Strategy-1:-matrix-indexing"><a class="docs-heading-anchor" href="#Strategy-1:-matrix-indexing">Strategy 1: matrix indexing</a><a id="Strategy-1:-matrix-indexing-1"></a><a class="docs-heading-anchor-permalink" href="#Strategy-1:-matrix-indexing" title="Permalink"></a></h4><p>The first strategy is to index directly, using the vector of global dofs, into the global matrix:</p><pre><code class="language-julia hljs">function assemble_v1(_, K, dofs, Ke)
    K[dofs, dofs] += Ke
    return
end</code></pre><p>This looks very simple, but it is very inefficient (as the numbers will show later). To understand why the operation <code>K[dofs, dofs] += Ke</code> (with <code>K</code> being a sparse matrix) is so slow we can dig into the details.</p><p>In Julia there is no &quot;<code>+=</code>&quot;-operation and so <code>x += y</code> is identical to <code>x = x + y</code>. Translating this to our example we have</p><pre><code class="language-julia hljs">K[dofs, dofs] = K[dofs, dofs] + Ke</code></pre><p>We can break down this a bit further into these equivalent three steps:</p><pre><code class="language-julia hljs">tmp1 = K[dofs, dofs]   # 1
tmp2 = tmp1 + Ke       # 2
K[dofs, dofs] = tmp2   # 3</code></pre><p>Now the problem with this strategy becomes a bit more obvious:</p><ul><li>In line 1 there is first an allocation of a new matrix (<code>tmp1</code>) followed by indexing into <code>K</code> to copy elements from <code>K</code> to <code>tmp1</code>. Both of these operations are rather costly: allocations should always be minimized in tight loops, and indexing into a sparse matrix is non-trivial due to the data structure. In addition, since the <code>dofs</code> vector contains the global indices (which are neither sorted nor consecutive) we have a random access pattern.</li><li>In line 2 there is another allocation of a matrix (<code>tmp2</code>) for the result of the addition of <code>tmp1</code> and <code>Ke</code>.</li><li>In line 3 we again need to index into the sparse matrix to copy over the elements from <code>tmp2</code> to <code>K</code>. This essentially duplicates the indexing effort from line 1 since we need to lookup the same locations in <code>K</code> again.</li></ul><div class="admonition is-info"><header class="admonition-header">Broadcasting</header><div class="admonition-body"><p>Using <a href="https://docs.julialang.org/en/v1/manual/arrays/#Broadcasting">broadcasting</a>, e.g. <code>K[dofs, dofs] .+= Ke</code> is an alternative to the above, and resembles a <code>+=</code>-operation. In theory this should be as efficient as the explicit loop presented in the next section.</p></div></div><h4 id="Strategy-2:-scalar-indexing"><a class="docs-heading-anchor" href="#Strategy-2:-scalar-indexing">Strategy 2: scalar indexing</a><a id="Strategy-2:-scalar-indexing-1"></a><a class="docs-heading-anchor-permalink" href="#Strategy-2:-scalar-indexing" title="Permalink"></a></h4><p>A variant of the first strategy is to explicitly loop over the indices and add the elements individually as scalars:</p><pre><code class="language-julia hljs">function assemble_v2(_, K, dofs, Ke)
    for (i, I) in pairs(dofs)
        for (j, J) in pairs(dofs)
            K[I, J] += Ke[i, j]
        end
    end
    return
end</code></pre><p>The core operation, <code>K[I, J] += Ke[i, j]</code>, can still be broken down into three equivalent steps:</p><pre><code class="language-julia hljs">tmp1 = K[I, J]
tmp2 = tmp1 + Ke[i, j]
K[I, J] = tmp2</code></pre><p>The key difference here is that we index using integers (<code>I</code>, <code>J</code>, <code>i</code>, and <code>j</code>) which means that <code>tmp1</code> and <code>tmp2</code> are scalars which don&#39;t need to be allocated on the heap. This stragety thus eliminates all allocations that were present in the first strategy. However, we still lookup the same location in <code>K</code> twice, and we still have a random access pattern.</p><h4 id="Strategy-3:-scalar-indexing-with-single-lookup"><a class="docs-heading-anchor" href="#Strategy-3:-scalar-indexing-with-single-lookup">Strategy 3: scalar indexing with single lookup</a><a id="Strategy-3:-scalar-indexing-with-single-lookup-1"></a><a class="docs-heading-anchor-permalink" href="#Strategy-3:-scalar-indexing-with-single-lookup" title="Permalink"></a></h4><p>To improve on the second strategy we will get rid of the double lookup into the sparse matrix <code>K</code>. While Julia doesn&#39;t have a &quot;<code>+=</code>&quot;-operation, Ferrite has an internal <code>addindex!</code>-function which does exactly what we want: it adds a value to a specific location in a sparse matrix using a single lookup.</p><pre><code class="language-julia hljs">function assemble_v3(_, K, dofs, Ke)
    for (i, I) in pairs(dofs)
        for (j, J) in pairs(dofs)
            Ferrite.addindex!(K, Ke[i, j], I, J)
        end
    end
    return
end</code></pre><p>With this method we remove the double lookup, but the issue of random access patterns still remains.</p><h4 id="Strategy-4:-using-an-assembler"><a class="docs-heading-anchor" href="#Strategy-4:-using-an-assembler">Strategy 4: using an assembler</a><a id="Strategy-4:-using-an-assembler-1"></a><a class="docs-heading-anchor-permalink" href="#Strategy-4:-using-an-assembler" title="Permalink"></a></h4><p>Finally, the last strategy we consider uses an assembler. The assembler is a specific datastructure that pre-allocates some workspace to make the assembly more efficient:</p><pre><code class="language-julia hljs">function assemble_v4(assembler, _, dofs, Ke)
    assemble!(assembler, dofs, Ke)
    return
end</code></pre><p>The extra workspace inside the assembler is used to sort the dofs when <code>assemble!</code> is called. After sorting it is possible to loop over the sparse matrix data structure and insert all elements of <code>Ke</code> in one go instead of having to lookup locations randomly.</p><h3 id="Single-element-assembly"><a class="docs-heading-anchor" href="#Single-element-assembly">Single element assembly</a><a id="Single-element-assembly-1"></a><a class="docs-heading-anchor-permalink" href="#Single-element-assembly" title="Permalink"></a></h3><p>First we will compare the four functions above for a single assembly operation, i.e. inserting one local matrix into the global matrix. For this we simply create a random local matrix since we are not conserned with the actual values. We also pick the &quot;middle&quot; element and extract the dofs for that element. Finally, an assembler is created with <code>start_assemble</code> to use with the fourth strategy.</p><pre><code class="language-julia hljs">dofs_per_cell = ndofs_per_cell(dh)
const Ke = rand(dofs_per_cell, dofs_per_cell)
const dofs = celldofs(dh, N * N ÷ 2)

const assembler = start_assemble(K)</code></pre><p>We use BenchmarkTools to measure the performance:</p><pre><code class="language-julia hljs">using BenchmarkTools

@btime assemble_v1(assembler, K, dofs, Ke) evals = 10 setup = fill!(K, 0)
@btime assemble_v2(assembler, K, dofs, Ke) evals = 10 setup = fill!(K, 0)
@btime assemble_v3(assembler, K, dofs, Ke) evals = 10 setup = fill!(K, 0)
@btime assemble_v4(assembler, K, dofs, Ke) evals = 10 setup = fill!(K, 0)</code></pre><p>The results below are obtained on an Macbook Pro with an Apple M3 CPU.</p><pre><code class="nohighlight hljs">606.438 μs (36 allocations: 7.67 MiB)
283.300 ns (0 allocations: 0 bytes)
158.300 ns (0 allocations: 0 bytes)
 83.400 ns (0 allocations: 0 bytes)</code></pre><p>The results match what we expect based on the explanations above:</p><ul><li>Between strategy 1 and 2 we got rid of the allocations completely and decreased the time with a factor of 2100(!).</li><li>Between strategy 2 and 3 we got rid of the double lookup and decreased the time with another factor of almost 2.</li><li>Between strategy 3 and 4 we got rid of the random lookup order and decreased the time with another factor of almost 2.</li></ul><p>The most important thing for this benchmark is to get rid of the allocations. By using an assembler instead of doing the naive thing we reduce the runtime with a factor of more than 7000(!!) in total.</p><h3 id="Full-system-assembly"><a class="docs-heading-anchor" href="#Full-system-assembly">Full system assembly</a><a id="Full-system-assembly-1"></a><a class="docs-heading-anchor-permalink" href="#Full-system-assembly" title="Permalink"></a></h3><p>We will now compare the four strategies in a more realistic scenario where we assemble all elements. This is to put the assembly performance in relation to other operations in the finite element program. After all, assembly performance might not matter in the end if other things dominate the runtime anyway.</p><p>For this comparison we simply consider the heat equation (see <a href="../../tutorials/heat_equation/">Tutorial 1: Heat equation</a>) and assemble the global matrix.</p><pre><code class="language-julia hljs">function assemble_system!(assembler_function::F, K, dh, cv) where {F}
    assembler = start_assemble(K)
    ke = zeros(ndofs_per_cell(dh), ndofs_per_cell(dh))
    n = getnbasefunctions(cv)
    for cell in CellIterator(dh)
        reinit!(cv, cell)
        ke .= 0
        for qp in 1:getnquadpoints(cv)
            dΩ = getdetJdV(cv, qp)
            for i in 1:n
                ∇ϕi = shape_gradient(cv, qp, i)
                for j in 1:n
                    ∇ϕj = shape_gradient(cv, qp, j)
                    ke[i, j] += ( ∇ϕi ⋅ ∇ϕj ) * dΩ
                end
            end
        end
        assembler_function(assembler, K, celldofs(cell), ke)
    end
    return
end</code></pre><p>Finally, we need cellvalues for the field in order to perform the integration:</p><pre><code class="language-julia hljs">qr = QuadratureRule{RefTriangle}(2)
const cellvalues = CellValues(qr, ip)</code></pre><p>We can now time the four assembly strategies:</p><pre><code class="language-julia hljs">@time assemble_system!(assemble_v1, K, dh, cellvalues)
@time assemble_system!(assemble_v2, K, dh, cellvalues)
@time assemble_system!(assemble_v3, K, dh, cellvalues)
@time assemble_system!(assemble_v4, K, dh, cellvalues)</code></pre><p>We then obtain the following results (running on the same machine as above):</p><pre><code class="nohighlight hljs">12.175625 seconds (719.99 k allocations: 149.809 GiB, 11.59% gc time)
 0.009313 seconds (8 allocations: 928 bytes)
 0.006055 seconds (8 allocations: 928 bytes)
 0.004530 seconds (10 allocations: 1.062 KiB)</code></pre><p>This follows the same trend as for the benchmarks for individual cell assembly and shows that the efficiency of the assembly strategy is crucial for the overall performance of the program. In particular this benchmark shows that allocations in such a tight loop from the first strategy is very costly and puts a strain on the garbage collector: 11% of the time is spent in GC instead of crunching numbers.</p><p>It should of course be noted that the more expensive the element routine is, the less the performance of the assembly strategy matters for the total runtime. However, there are no reason not to use the fastest method given that it is readily available in Ferrite.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../sparse_matrix/">« Sparsity pattern and sparse matrices</a><a class="docs-footer-nextpage" href="../boundary_conditions/">Boundary and initial conditions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Wednesday 26 February 2025 20:56">Wednesday 26 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
